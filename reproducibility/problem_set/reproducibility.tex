\documentclass[11pt]{article}
\usepackage{amsmath, amssymb, graphicx, hyperref}
\usepackage{enumitem}
\setlist{nosep}
\usepackage[margin=1in]{geometry}

\title{ Reproducible Research Workflows}
\author{ }
\date{ }



\begin{document}
\maketitle

\noindent \textbf{Note on data.} This assignment uses a \textbf{synthetic} voter-turnout dataset provided by \texttt{poliscitools} (via \texttt{example\_data}). The goal is to practice reproducibility tooling (dependency management, logging, packaging outputs, and replication checks)---not to draw substantive inferences about real voters.

\section*{Conceptual Questions}
Please write three to ten sentence explanations for each of the following questions. \textbf{You are only required to answer ONE of the two questions below.} \bigskip
 
\begin{enumerate}

\item Explain what problem \texttt{renv} solves in reproducible research. In your answer, describe what information is stored in \texttt{renv.lock}, what \texttt{renv::restore()} does, and why sharing code without dependency versions can fail replication even when the analysis is ``correct.''

\item Explain why logging (e.g., \texttt{logger}) is part of professional, reproducible analysis. Give two concrete examples of what you would log in a pipeline (inputs, parameters, random seeds, file paths, model summaries, warnings), and explain how logs help diagnose non-reproducible results.

  \end{enumerate}


\section*{Applied Exercises}
Use the code in the week's code tutorial and the lecture slides to answer the following questions.\bigskip

  \begin{enumerate}
  \setcounter{enumi}{2}

\item \textbf{Reproducible project setup: dependencies, directories, and end-to-end run.}
Using the provided reproducibility script:
\begin{itemize}
  \item Create a clean project folder and initialize \texttt{renv} (or restore from an existing \texttt{renv.lock} if provided).
  \item Run the full pipeline by sourcing the script and running \texttt{run\_analysis()}.
  \item Verify that the following artifacts are produced:
  \begin{itemize}
    \item \texttt{data/raw/voter\_data.csv} and \texttt{data/processed/cleaned\_voter\_data.csv},
    \item figures in \texttt{outputs/figures/},
    \item tables in \texttt{outputs/tables/} (including the bootstrap output),
    \item \texttt{outputs/session\_info.txt} and \texttt{analysis\_log.txt}.
  \end{itemize}
  \item Briefly describe (3--6 sentences) what each folder is for (\texttt{data/raw}, \texttt{data/processed}, \texttt{outputs/figures}, \texttt{outputs/tables}) and why the separation matters for reproducibility.
\end{itemize}

\item \textbf{Extend outputs: add one additional plot and one additional table.}
Modify the script to generate:
\begin{itemize}
  \item \textbf{One additional plot} saved to \texttt{outputs/figures/}. Choose one:
  \begin{enumerate}
    \item a plot of bootstrap coefficient distributions (from \texttt{boot\_coef}),
    \item a turnout plot broken down by two dimensions (e.g., party $\times$ age\_group),
    \item a plot showing model residuals or predicted vs.\ observed turnout.
  \end{enumerate}
  \item \textbf{One additional table} saved to \texttt{outputs/tables/}. Choose one:
  \begin{enumerate}
    \item a turnout summary table by party and age group,
    \item a table of regression coefficients with confidence intervals (or bootstrap intervals),
    \item a missingness summary table for the cleaned dataset.
  \end{enumerate}
  \item In 3--6 sentences, explain how these additions improve the interpretability and auditability of the analysis.
\end{itemize}

\item \textbf{Reproducibility checks: logging + repeated runs.}
Use the reproducibility testing ideas in the script:
\begin{itemize}
  \item Run the analysis multiple times (at least 3) using the provided reproducibility testing function (or an equivalent workflow you implement).
  \item Report whether results are identical across runs. If they are not identical, identify \textbf{one} source of non-determinism and fix it (e.g., missing \texttt{set.seed()}, randomness in resampling, unstable ordering).
  \item Add at least \textbf{two} additional log messages (\texttt{log\_info}) that record key intermediate facts (e.g., row counts before/after cleaning, number of bootstrap iterations completed, output file paths written).
  \item In 5--8 sentences, explain what you learned from the reproducibility check and what would still threaten reproducibility across different machines.
\end{itemize}

\item \textbf{Challenge Question (Optional --- if you finish early):}
Containerize and/or automate reproducibility.
Choose \textbf{ONE} of the following:
\begin{enumerate}
  \item \textbf{Docker replication.} Use the provided \texttt{create\_dockerfile()} logic (or write your own Dockerfile) to run the full analysis in a container. Provide evidence it worked (e.g., outputs created in \texttt{outputs/} and a short excerpt of container logs). In 4--8 sentences, explain what Docker adds beyond \texttt{renv}.
  \item \textbf{GitHub Actions replication.} Set up a minimal GitHub Actions workflow that (i) installs R, (ii) restores \texttt{renv}, and (iii) runs \texttt{run\_analysis()}. Provide the workflow YAML file and a screenshot (or log excerpt) showing a successful run.
\end{enumerate}

\end{enumerate}

\noindent \textbf{Submission:} Push your code changes to GitHub and submit a link to your repository. Your repository should include \texttt{renv.lock}, your modified script(s), and the updated outputs you created (figures/tables). Do not commit large, unnecessary intermediate files.

\end{document}
